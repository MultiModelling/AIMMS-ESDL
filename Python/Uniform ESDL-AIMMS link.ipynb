{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c4399f",
   "metadata": {},
   "source": [
    "# Uniform ESDL-Aimms connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35080a6",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is a ready made code script that transforms an esdl to a database that can be imported to into AIMMS. It uses two python packages 'pyesdl' and 'pymysql' made by respectively TNO and Mysql to transform an esdl file to SQL tables that can be read by AIMMS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d4f1b",
   "metadata": {},
   "source": [
    "## **Sensitive Quomare user information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db6414f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "337d6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DB = \"TESTDB_ESDL_to_AIMMS\"\n",
    "\n",
    "\n",
    "Filename = <<Your_ESDL>>\n",
    "Outputfile = <<Your_Output>>\n",
    "Host = <<Your_Host>>\n",
    "User = <<Your_User>>\n",
    "PW = <<Your_Password>>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da1b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message= \".*pandas only support SQLAlchemy connectable.*\")\n",
    "\n",
    "\n",
    "\n",
    "conn = pymysql.connect(\n",
    "    host= Host,\n",
    "    user=User,\n",
    "    password=PW)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9bdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8afe7b6",
   "metadata": {},
   "source": [
    "### Simple function that runs an SQL command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb550c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_sql(query):\n",
    "    try:\n",
    "        result = pd.read_sql(query, conn)\n",
    "        return result\n",
    "    except pymysql.Error as e:\n",
    "        print(\"Error: unable to fetch data %d: %s\" %(e.args[0], e.args[1]))\n",
    "\n",
    "# if __name__ == \"__main__\" :\n",
    "#     sql = get_sql('SELECT * FROM TESTDB_AIMMS.Arcs')\n",
    "#     df = pd.DataFrame(sql)\n",
    "#     print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423701db",
   "metadata": {},
   "source": [
    "### Function that creates a new database with DB the new name of the database and with SetofTables a list of all the tables in de database and set of attributes a list of tuples of attributes of every table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a35c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_AIMMS_sql(DB, SetofTables,SetofAttributes):\n",
    "    def __init__(self, DB):\n",
    "        self.DB = DB\n",
    "    cursor.execute('DROP DATABASE IF EXISTS ' + DB +';')\n",
    "    cursor.execute('create database ' + DB +';')\n",
    "    conn.select_db(DB)\n",
    "\n",
    "#     query = \"SELECT concat('DROP TABLE IF EXISTS `', table_name, '`;') FROM information_schema.tables WHERE table_schema = '\"+ DB + \"';\"\n",
    "#     cursor.execute(query)\n",
    "#     Tables = cursor.fetchall()\n",
    "#     for i in Tables:\n",
    "#         cursor.execute(i[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        query = []\n",
    "        for i in range(len(SetofTables)):\n",
    "            query.append('create table ' + SetofTables[i] + '(' + ','.join(SetofAttributes[i]) +')')\n",
    "#         query = [\n",
    "# '        create table Assets(aggregated varchar(100),aggregationCount varchar(100),assetType varchar(100),commissioningDate varchar(100),decommissioningDate varchar(100),description varchar(100),id varchar(100) Primary Key,installationDuration varchar(100),manufacturer varchar(100),name varchar(100),originalIdInSource varchar(100),owner varchar(100),shortName varchar(100),state varchar(100),surfaceArea varchar(100),technicalLifetime varchar(100));',\n",
    "# '        create table Arcs(NameNode1 varchar(100), idNode1 varchar(100), nameNode2 varchar(100), idNode2 varchar(100), Carrier varchar(100), maxPower varchar(100), simultaneousPower varchar(100),PRIMARY KEY (idNode1, idNode2));',\n",
    "# '        create table Producers(id varchar(100) Primary Key, name varchar(100), prodType varchar(100), OperationalHours varchar(100), fullLoadHours varchar(100), power varchar(100));',\n",
    "# '        create table Conversions(id varchar(100) Primary Key,name varchar(100), efficiency varchar(100), power varchar(100));',\n",
    "# '        create table Consumers(id varchar(100) Primary Key,name varchar(100), consType varchar(100), power varchar(100));',\n",
    "# '        create table Transports(id varchar(100) Primary Key,name varchar(100), efficiency varchar(100), capacity varchar(100));',\n",
    "# '        create table Products(stateOfMatter varchar(100), energyCarrierType varchar(100), id varchar(100) Primary Key,  emission varchar(100), name varchar(100), energyContent varchar(100));',\n",
    "# '        create table Buildings(id varchar(100) Primary Key, floorArea varchar(100), buildingYear varchar(100), originalIdInSource varchar(100),surfaceArea varchar(100), name varchar(100), height varchar(100), asset1 varchar(100), asset2 varchar(100),asset3 varchar(100),asset4 varchar(100));']\n",
    "        for i in query:\n",
    "            cursor.execute(i)\n",
    "        \n",
    "        #Progress update\n",
    "        print('SQL-file created from ESDL-file')\n",
    "        print(query)\n",
    "    except pymysql.Error as e:\n",
    "            print(\"Error: unable to create table %d: %s\" %(e.args[0], e.args[1]))\n",
    "            \n",
    "# if __name__ == \"__main__\" :\n",
    "#     my_list =  [('id varchar(100)','name varchar(100)'), ('id varchar(100)','name varchar(100)'), ('id varchar(100)','name varchar(100)'), ('id varchar(100)','name varchar(100)'), ('id varchar(100)','name varchar(100)'), ('id varchar(100)','name varchar(100)'), ('id varchar(100)','name varchar(100)'), ('id varchar(100)','name varchar(100)')]\n",
    "#     create_AIMMS_sql('TESTDB_AIMMS',['Assets', 'Arcs', 'Producers', 'Conversions', 'Consumers', 'Transports', 'Products', 'Buildings'], my_list\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975aaa1",
   "metadata": {},
   "source": [
    "### Function that writes a tuple (val) of all lengths to database (DB) in Table (Sheet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343cd323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_table_to_Sql(DB, Sheet, val):\n",
    "    # Build query\n",
    "    numofcol = get_sql(\n",
    "        \"SELECT COUNT(*) as NumberofCol from INFORMATION_SCHEMA.COLUMNS where table_schema = '\"+ DB +\"' and table_name = '\" + Sheet + \"';\")\n",
    "    numb = numofcol['NumberofCol'][0]\n",
    "    query = 'INSERT INTO ' + DB + '.' + Sheet + ' VALUES (' + numb * '%s,'\n",
    "    query = query[:-1] + ');'\n",
    "    print(query)\n",
    "    # Check query\n",
    "    cursor.executemany(query, val)\n",
    "    print('INSERT ' +Sheet+ ' COMPLETE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09ee943a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "SQL-file created from ESDL-file\n",
      "['create table Assets(id varchar(100) Primary key,aggregated varchar(100),aggregationCount varchar(100),assetType varchar(100),commissioningDate varchar(100),decommissioningDate varchar(100),description varchar(100),installationDuration varchar(100),manufacturer varchar(100),name varchar(100),originalIdInSource varchar(100),owner varchar(100),shortName varchar(100),state varchar(100),surfaceArea varchar(100),technicalLifetime varchar(100),costInformation_id varchar(100))', 'create table Producers(id varchar(100) Primary key,name varchar(100),prodType varchar(100),operationalHours varchar(100),fullLoadHours varchar(100),power varchar(100))', 'create table Consumers(id varchar(100)  Primary Key,name varchar(100),consType varchar(100),power varchar(100))', 'create table ConsumerProfiles(id_consumer varchar(100),name_consumer varchar(100),dataSource varchar(100),endDate varchar(100),field varchar(100),filters varchar(100),host varchar(100),id varchar(100),interpolationMethod varchar(100),measurement varchar(100),multiplier varchar(100),name varchar(100),profileQuantityAndUnit varchar(100),profileType varchar(100),startDate varchar(100))', 'create table Transports(id varchar(100)  Primary Key,name varchar(100),efficiency varchar(100),capacity varchar(100))', 'create table Arcs(Node1_name varchar(100),Node1_id varchar(100),Outport_name varchar(100),Outport_id varchar(100),Node2_name varchar(100),Node2_id varchar(100),Inport_name varchar(100),Inport_id varchar(100),PRIMARY KEY (Node1_id, Node2_id),carrier varchar(100),carrier_id varchar(100),CostDummy varchar(100))', 'create table Carriers(id varchar(100) Primary Key,name varchar(100))', 'create table ElectricityCommodities(cost varchar(100),dataSource varchar(100),emission varchar(100),emissionUnit varchar(100),id varchar(100) Primary Key,name varchar(100),renewableFactor varchar(100),voltage varchar(100))', 'create table Commodities(id varchar(100)  Primary Key,name varchar(100))', 'create table CostInformations(AssetId varchar(100),AssetName varchar(100),developmentCosts varchar(100),discountRate varchar(100),fixedMaintenanceCosts varchar(100),fixedOperationalAndMaintenanceCosts varchar(100),fixedOperationalCosts varchar(100),id varchar(100),installationCosts varchar(100),investmentCosts varchar(100),marginalCosts varchar(100),variableMaintenanceCosts varchar(100),variableOperationalAndMaintenanceCosts varchar(100),variableOperationalCosts varchar(100))', 'create table Constraints(Node_Id varchar(100),Node_Name varchar(100),Constraint_Id varchar(100),Constraint_Name varchar(100),Constraint_Attribute varchar(100),range_Id varchar(100),range_name varchar(100),max varchar(100),min varchar(100))', 'create table QuantityAndUnitTypes(CarrierId varchar(100),CarrierDescription varchar(100),type varchar(100),description varchar(100),id varchar(100),multiplier varchar(100),perMultiplier varchar(100),perScope varchar(100),perTimeUnit varchar(100),perUnit varchar(100),physicalQuantity varchar(100),unit varchar(100))']\n",
      "Exporting: Assets\n",
      "INSERT INTO TESTDB_ESDL_to_AIMMS.Assets VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s);\n",
      "INSERT Assets COMPLETE\n",
      "Exporting: Producers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO TESTDB_ESDL_to_AIMMS.Producers VALUES (%s,%s,%s,%s,%s,%s);\n",
      "INSERT Producers COMPLETE\n",
      "Exporting: Consumers\n",
      "INSERT INTO TESTDB_ESDL_to_AIMMS.Consumers VALUES (%s,%s,%s,%s);\n",
      "INSERT Consumers COMPLETE\n",
      "Exporting: ConsumerProfiles\n",
      "INSERT INTO TESTDB_ESDL_to_AIMMS.ConsumerProfiles VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s);\n",
      "INSERT ConsumerProfiles COMPLETE\n",
      "Exporting: Transports\n",
      "INSERT INTO TESTDB_ESDL_to_AIMMS.Transports VALUES (%s,%s,%s,%s);\n",
      "INSERT Transports COMPLETE\n",
      "Exporting: Arcs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO TESTDB_ESDL_to_AIMMS.Arcs VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s);\n",
      "INSERT Arcs COMPLETE\n",
      "Exporting: Carriers\n",
      "INSERT INTO TESTDB_ESDL_to_AIMMS.Carriers VALUES (%s,%s);\n",
      "INSERT Carriers COMPLETE\n",
      "Exporting: ElectricityCommodities\n",
      "INSERT INTO TESTDB_ESDL_to_AIMMS.ElectricityCommodities VALUES (%s,%s,%s,%s,%s,%s,%s,%s);\n",
      "INSERT ElectricityCommodities COMPLETE\n",
      "Exporting: Commodities\n",
      "INSERT INTO TESTDB_ESDL_to_AIMMS.Commodities VALUES (%s,%s);\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT Commodities COMPLETE\n",
      "Exporting: CostInformations\n",
      "INSERT INTO TESTDB_ESDL_to_AIMMS.CostInformations VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s);\n",
      "INSERT CostInformations COMPLETE\n",
      "Exporting: Constraints\n",
      "INSERT INTO TESTDB_ESDL_to_AIMMS.Constraints VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s);\n",
      "INSERT Constraints COMPLETE\n",
      "Exporting: QuantityAndUnitTypes\n",
      "INSERT INTO TESTDB_ESDL_to_AIMMS.QuantityAndUnitTypes VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s);\n",
      "INSERT QuantityAndUnitTypes COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jul 19 09:29:13 2022\n",
    "\n",
    "@author: Stijn\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "from esdl.esdl_handler import EnergySystemHandler\n",
    "from esdl import esdl\n",
    "\n",
    "\n",
    "\n",
    "def ExtractDataESDL(TableName, Instances, SetofAttributes, SetofTables, SetofValues):\n",
    "    \n",
    "    if Instances == []:\n",
    "        return\n",
    "    valInstance =[]\n",
    "    for m in Instances:\n",
    "        temp = tuple()\n",
    "        for d in dir(m):\n",
    "            e = getattr(m, d)\n",
    "            if e == None:\n",
    "                temp+= (None,)\n",
    "            else:\n",
    "                if e == object:\n",
    "                    temp+=(e.id)\n",
    "                temp+=(e,)\n",
    "        valInstance.append(temp)\n",
    "    \n",
    "    InstanceAttr = tuple()\n",
    "    for d in dir(Instances[0]):\n",
    "        if d == 'id':\n",
    "            InstanceAttr += (d  + ' varchar(100) Primary Key',)\n",
    "        else:\n",
    "            InstanceAttr += (d  + ' varchar(100)',)\n",
    "    \n",
    "    SetofAttributes.append(InstanceAttr)\n",
    "    SetofTables.append(TableName)\n",
    "    SetofValues.append(valInstance)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    esh = EnergySystemHandler()\n",
    "    es = esh.load_file(Filename)\n",
    "    # xml_string = esh.to_string()\n",
    "    #print(xml_string)\n",
    "    \n",
    "    SetofTables = []\n",
    "    SetofAttributes = []\n",
    "    SetofValues = []\n",
    "    \n",
    "\n",
    "    Assets = esh.get_all_instances_of_type(esdl.EnergyAsset)\n",
    "    valAssets = [[n.id,\n",
    "                  n.aggregated, \n",
    "                  n.aggregationCount, \n",
    "                  n.assetType, \n",
    "                  n.commissioningDate,\n",
    "                  n.decommissioningDate, \n",
    "                  n.description,  \n",
    "                  n.installationDuration, \n",
    "                  n.manufacturer, \n",
    "                  n.name, \n",
    "                  n.originalIdInSource, \n",
    "                  n.owner,\n",
    "                  n.shortName, \n",
    "                  n.state, \n",
    "                  n.surfaceArea, \n",
    "                  n.technicalLifetime, \n",
    "                  n.costInformation] \n",
    "                for n in Assets]\n",
    "    if(Assets != []):\n",
    "        SetofTables.append('Assets')\n",
    "        SetofAttributes.append(('id varchar(100) Primary key' ,\n",
    "                                'aggregated varchar(100)', \n",
    "                                'aggregationCount varchar(100)', \n",
    "                                'assetType varchar(100)', \n",
    "                                'commissioningDate varchar(100)', \n",
    "                                'decommissioningDate varchar(100)' , \n",
    "                                'description varchar(100)' ,  \n",
    "                                'installationDuration varchar(100)' , \n",
    "                                'manufacturer varchar(100)' , \n",
    "                                'name varchar(100)' , \n",
    "                                'originalIdInSource varchar(100)' , \n",
    "                                'owner varchar(100)' , \n",
    "                                'shortName varchar(100)' ,\n",
    "                                'state varchar(100)' , \n",
    "                                'surfaceArea varchar(100)' , \n",
    "                                'technicalLifetime varchar(100)',\n",
    "                                'costInformation_id varchar(100)'))\n",
    "        SetofValues.append(valAssets)\n",
    "    \n",
    "    Producers = esh.get_all_instances_of_type(esdl.Producer)\n",
    "    valProducers = [(n.id, \n",
    "                     n.name, \n",
    "                     n.prodType, \n",
    "                     n.operationalHours, \n",
    "                     n.fullLoadHours, \n",
    "                     n.power)\n",
    "                for n in Producers]\n",
    "    if(Producers != []):\n",
    "        SetofAttributes.append(('id varchar(100) Primary key', \n",
    "                                'name varchar(100)', \n",
    "                                'prodType varchar(100)', \n",
    "                                'operationalHours varchar(100)', \n",
    "                                'fullLoadHours varchar(100)', \n",
    "                                'power varchar(100)'))\n",
    "        SetofTables.append('Producers')\n",
    "        SetofValues.append(valProducers)\n",
    "    \n",
    "    Consumers = esh.get_all_instances_of_type(esdl.Consumer)\n",
    "    valConsumers = [(n.id, n.name, n.consType, n.power) \n",
    "                for n in Consumers]\n",
    "\n",
    "    if(Consumers != []):    \n",
    "        SetofAttributes.append(('id varchar(100)  Primary Key', \n",
    "                                'name varchar(100)', \n",
    "                                'consType varchar(100)', \n",
    "                                'power varchar(100)'))\n",
    "        SetofTables.append('Consumers')\n",
    "        SetofValues.append(valConsumers)\n",
    "    \n",
    "    Singlevalueprofiles = esh.get_all_instances_of_type(esdl.SingleValue)\n",
    "    ConsumerProfiles = []\n",
    "    valConsumerProfiles = []\n",
    "    for n in Consumers:\n",
    "        for p in n.port:\n",
    "            for pr in p.profile:\n",
    "                ConsumerProfiles.append(pr)\n",
    "                if(pr in Singlevalueprofiles):\n",
    "                    valConsumerProfiles.append((n.id,\n",
    "                                                n.name,\n",
    "                                                'null', \n",
    "                                                'null', \n",
    "                                                'null', \n",
    "                                                'null', \n",
    "                                                'null', \n",
    "                                                pr.id, \n",
    "                                                'null', \n",
    "                                                'null', \n",
    "                                                pr.value,\n",
    "                                                pr.name,\n",
    "                                                'null', \n",
    "                                                'null', \n",
    "                                                'null'))\n",
    "                else:\n",
    "                    valConsumerProfiles.append((n.id,\n",
    "                                                n.name,\n",
    "                                                pr.dataSource, \n",
    "                                                pr.endDate, \n",
    "                                                pr.field,pr.filters, \n",
    "                                                pr.host,\n",
    "                                                pr.id, \n",
    "                                                pr.interpolationMethod, \n",
    "                                                pr.measurement,\n",
    "                                                pr.multiplier,\n",
    "                                                pr.name,\n",
    "                                                pr.profileQuantityAndUnit,\n",
    "                                                pr.profileType,\n",
    "                                                pr.startDate))\n",
    "    if(valConsumerProfiles != []):    \n",
    "        SetofAttributes.append(('id_consumer varchar(100)', \n",
    "                                'name_consumer varchar(100)',\n",
    "                                'dataSource varchar(100)', \n",
    "                                'endDate varchar(100)', \n",
    "                                'field varchar(100)', \n",
    "                                'filters varchar(100)', \n",
    "                                'host varchar(100)', \n",
    "                                'id varchar(100)', \n",
    "                                'interpolationMethod varchar(100)', \n",
    "                                'measurement varchar(100)', \n",
    "                                'multiplier varchar(100)', \n",
    "                                'name varchar(100)',  \n",
    "                                'profileQuantityAndUnit varchar(100)', \n",
    "                                'profileType varchar(100)', \n",
    "                                'startDate varchar(100)'))\n",
    "        SetofTables.append('ConsumerProfiles')\n",
    "        SetofValues.append(valConsumerProfiles)\n",
    "    \n",
    "    Conversions = esh.get_all_instances_of_type(esdl.Conversion)\n",
    "    valConversions = [(n.id, n.name, n.efficiency, n.power) \n",
    "                for n in Conversions]\n",
    "    if(Conversions != []):    \n",
    "        SetofAttributes.append(('id varchar(100)  Primary Key', \n",
    "                                'name varchar(100)', \n",
    "                                'efficiency varchar(100)', \n",
    "                                'power varchar(100)'))\n",
    "        SetofTables.append('Conversions')\n",
    "        SetofValues.append(valConversions)\n",
    "    \n",
    "    Transports = esh.get_all_instances_of_type(esdl.Transport)\n",
    "    valTransports = [(n.id, \n",
    "                      n.name, \n",
    "                      n.efficiency, \n",
    "                      n.capacity) \n",
    "                for n in Transports]\n",
    "    if(Transports != []):       \n",
    "        SetofAttributes.append(('id varchar(100)  Primary Key', \n",
    "                                'name varchar(100)', \n",
    "                                'efficiency varchar(100)', \n",
    "                                'capacity varchar(100)'))\n",
    "        SetofTables.append('Transports')\n",
    "        SetofValues.append(valTransports)\n",
    "    \n",
    "    Arcs = esh.get_all_instances_of_type(esdl.OutPort)\n",
    "    valArcs = [(a.energyasset.name,\n",
    "                a.energyasset.id, \n",
    "                a.name, \n",
    "                a.id, \n",
    "                b.energyasset.name, \n",
    "                b.energyasset.id, \n",
    "                b.name, \n",
    "                b.id,\n",
    "                a.carrier.name, \n",
    "                a.carrier.id, \n",
    "                1)\n",
    "                 for a in Arcs for b in a.connectedTo]\n",
    "    if(Arcs != []): \n",
    "        SetofAttributes.append(('Node1_name varchar(100)', \n",
    "                                'Node1_id varchar(100)',\n",
    "                                'Outport_name varchar(100)',\n",
    "                                'Outport_id varchar(100)', \n",
    "                                'Node2_name varchar(100)', \n",
    "                                'Node2_id varchar(100)',\n",
    "                                'Inport_name varchar(100)', \n",
    "                                'Inport_id varchar(100)',\n",
    "                                'PRIMARY KEY (Node1_id, Node2_id)',\n",
    "                                'carrier varchar(100)',\n",
    "                                'carrier_id varchar(100)',\n",
    "                                'CostDummy varchar(100)'))\n",
    "        SetofTables.append('Arcs')\n",
    "        SetofValues.append(valArcs)\n",
    "#     valArcs = [(a.energyasset.name,\n",
    "#                 a.energyasset.id, \n",
    "#                 a.name, \n",
    "#                 a.id, \n",
    "#                 b.energyasset.name, \n",
    "#                 b.energyasset.id, \n",
    "#                 b.name, \n",
    "#                 b.id, \n",
    "#                 a.carrier.name, \n",
    "#                 a.carrier.id, \n",
    "#                 a.maxPower, \n",
    "#                 b.maxPower,\n",
    "#                 a.simultaneousPower,\n",
    "#                 b.simultaneousPower, \n",
    "#                 1)\n",
    "#                  for a in Arcs for b in a.connectedTo]\n",
    "#     SetofAttributes.append(('Node1_name varchar(100)', \n",
    "#                             'Node1_id varchar(100)',\n",
    "#                             'Outport_name varchar(100)',\n",
    "#                             'Outport_id varchar(100)', \n",
    "#                             'Node2_name varchar(100)', \n",
    "#                             'Node2_id varchar(100)',\n",
    "#                             'Inport_name varchar(100)', \n",
    "#                             'Inport_id varchar(100)',\n",
    "#                             'PRIMARY KEY (Node1_id, Node2_id)',\n",
    "#                             'carrier varchar(100)',\n",
    "#                             'carrier_id varchar(100)',\n",
    "#                             'maxPower_Out varchar(100)',\n",
    "#                             'maxPower_In varchar(100)', \n",
    "#                             'simultaneousPower_Out varchar(100)', \n",
    "#                             'simultaneousPower_In varchar(100)', \n",
    "#                             'CostDummy varchar(100)'))\n",
    "#     SetofTables.append('Arcs')\n",
    "#     SetofValues.append(valArcs)\n",
    "    \n",
    "#     Processes = esh.get_all_instances_of_type(esdl.InputOutputRelation)\n",
    "# #     Processes = [a.behaviour for a in Conversions]\n",
    "# #     print(Processes)\n",
    "#     valProcesses = []\n",
    "#     for a in Processes:\n",
    "#         for i in a.mainPortRelation:\n",
    "#             if type(i.port) == esdl.InPort:\n",
    "#                 itype = 'In'\n",
    "#             else:  itype = 'Out'\n",
    "#             tup = (a.mainPort.id, a.name, a.mainPortQuantityAndUnit, a.id, itype)\n",
    "#             for j in dir(i):\n",
    "#                 k = getattr(i, j)\n",
    "#                 if (type(k) == type(None) or type(k) == float):\n",
    "#                     tup += (k,)\n",
    "#                     print(j,k)\n",
    "#                 else: \n",
    "#                     tup += (k.id,)\n",
    "#             valProcesses.append(tup)\n",
    "#     if(Processes != []):        \n",
    "#         SetofAttributes.append(('mainPort  varchar(100)',\n",
    "#                                 'name  varchar(100)',\n",
    "#                                 'mainPortQuantityAndUnit  varchar(100)',\n",
    "#                                 'id  varchar(100)',\n",
    "#                                 'portType varchar(100)',\n",
    "#                                 'port varchar(100)',\n",
    "#                                 'quantityAndUnit varchar(100)', \n",
    "#                                 'ratio varchar(100)'))        \n",
    "#         SetofTables.append('Processes')\n",
    "#         SetofValues.append(valProcesses)\n",
    "    \n",
    "    \n",
    "    Processes = Conversions\n",
    "    valProcesses = []\n",
    "    for a in Conversions:\n",
    "        for b in a.port:\n",
    "            ratio = 1\n",
    "            if(a.behaviour):\n",
    "                for i in a.behaviour:\n",
    "                    mainport = i.mainPort\n",
    "                    for j in i.mainPortRelation:\n",
    "                        if (j.port == b):\n",
    "                            ratio = j.ratio\n",
    "                            break;\n",
    "            \n",
    "            else:\n",
    "                ratio = a.efficiency\n",
    "                mainport = a.port[1]\n",
    "            if type(a.port[0]) == esdl.InPort:\n",
    "                atype = 'In'\n",
    "            else:  atype = 'Out'\n",
    "            if type(b) == esdl.InPort:\n",
    "                btype = 'In'\n",
    "            else: btype = 'Out'\n",
    "            tup = ('null', mainport.id, mainport.carrier.id, atype, b.id, btype, a.id, a.name, ratio, b.carrier.id, b.carrier.name)\n",
    "            valProcesses.append(tup)\n",
    "    if(valProcesses != []):\n",
    "        SetofAttributes.append(('quantityAndUnit varchar(100)',\n",
    "                                'mainPortId varchar(100)',\n",
    "                                'mainPortCarrierId varchar(100)',\n",
    "                                'mainPortType varchar(100)',\n",
    "                                'portId varchar(100)',\n",
    "                                'portType varchar(100)',\n",
    "                                'conversionId varchar(100)',\n",
    "                                'conversionName varchar(100)',\n",
    "                                'ratio varchar(100)',\n",
    "                                'carrierId varchar(100)',\n",
    "                                'carrierName varchar(100)'))\n",
    "        SetofTables.append('Processes')\n",
    "        SetofValues.append(valProcesses)\n",
    "    \n",
    "    Carriers = esh.get_all_instances_of_type(esdl.Carrier)\n",
    "    valCarriers = [(p.id,\n",
    "                    p.name)\n",
    "                for p in Carriers]\n",
    "    if(Carriers != []):\n",
    "        SetofAttributes.append(('id varchar(100) Primary Key',\n",
    "                                'name varchar(100)'))\n",
    "        SetofTables.append('Carriers')\n",
    "        SetofValues.append(valCarriers)\n",
    "    \n",
    "    EnergyCarriers = esh.get_all_instances_of_type(esdl.EnergyCarrier)\n",
    "    valEnergyCarriers = [(p.id, \n",
    "                    p.stateOfMatter, \n",
    "                    p.energyCarrierType, \n",
    "                    p.emission, \n",
    "                    p.name , \n",
    "                    p.energyContent)\n",
    "                for p in EnergyCarriers]\n",
    "    if(EnergyCarriers != []):\n",
    "        SetofAttributes.append(('id varchar(100) Primary Key',\n",
    "                                'stateOfMatter varchar(100)', \n",
    "                                'energyCarrierType varchar(100)',  \n",
    "                                'emission varchar(100)',\n",
    "                                'name varchar(100)',\n",
    "                                'energyContent varchar(100)'))\n",
    "        SetofTables.append('EnergyCarriers')\n",
    "        SetofValues.append(valEnergyCarriers)\n",
    "    \n",
    "    GasCommodities = esh.get_all_instances_of_type(esdl.GasCommodity)\n",
    "    if(GasCommodities != []):\n",
    "        ExtractDataESDL('GasCommodities',GasCommodities, SetofAttributes, SetofTables, SetofValues)\n",
    "    \n",
    "    ElectricityCommodities = esh.get_all_instances_of_type(esdl.ElectricityCommodity)\n",
    "    if(ElectricityCommodities != []):\n",
    "        ExtractDataESDL('ElectricityCommodities',ElectricityCommodities, SetofAttributes, SetofTables, SetofValues)\n",
    "    \n",
    "    EnergyCommodities = esh.get_all_instances_of_type(esdl.EnergyCommodity)\n",
    "    if(EnergyCommodities != []):\n",
    "        ExtractDataESDL('EnergyCommodities',EnergyCommodities, SetofAttributes, SetofTables, SetofValues)\n",
    "    \n",
    "    Commodities = esh.get_all_instances_of_type(esdl.Commodity)\n",
    "    valCommodities = [(h.id, h.name)\n",
    "                 for h in Commodities]\n",
    "    if(Commodities != []):    \n",
    "        SetofAttributes.append(('id varchar(100)  Primary Key',\n",
    "                                 'name varchar(100)'))\n",
    "        SetofTables.append('Commodities')\n",
    "        SetofValues.append(valCommodities)\n",
    "    \n",
    "    Matters = esh.get_all_instances_of_type(esdl.Matter)\n",
    "    if(Matters != []): \n",
    "        ExtractDataESDL('Matters',Matters, SetofAttributes, SetofTables, SetofValues)\n",
    "#     Matters = esh.get_all_instances_of_type(esdl.Matter)\n",
    "#     valMatters =[]\n",
    "#     for m in Matters:\n",
    "#         temp = tuple()\n",
    "#         for d in dir(m):\n",
    "#             e = getattr(m, d)\n",
    "#             if e == None:\n",
    "#                 temp+= (None,)\n",
    "#             else:\n",
    "#                 temp+=(e,)\n",
    "#         valMatters.append(temp)\n",
    "    \n",
    "#     MatterAttr = tuple()\n",
    "#     for d in dir(Matters[0]):\n",
    "#         if d == 'id':\n",
    "#             MatterAttr += (d  + ' varchar(100) Primary Key',)\n",
    "#         else:\n",
    "#             MatterAttr += (d  + ' varchar(100)',)\n",
    "#     SetofAttributes.append(MatterAttr)\n",
    "#     SetofTables.append('Matters')\n",
    "#     SetofValues.append(valMatters)\n",
    "\n",
    "\n",
    "#     Buildings = esh.get_all_instances_of_type(esdl.Building)\n",
    "#     ExtractDataESDL('Buildings',Buildings, SetofAttributes, SetofTables, SetofValues)\n",
    "    Buildings = esh.get_all_instances_of_type(esdl.Building)\n",
    "    valBuildings = [(a.id, \n",
    "                     a.floorArea, \n",
    "                     a.buildingYear, \n",
    "                     a.originalIdInSource, \n",
    "                     a.surfaceArea,\n",
    "                     a.name, \n",
    "                     a.buildinginformation[0].height,\n",
    "                     a.geometry.exterior.point[0].lat, \n",
    "                     a.geometry.exterior.point[0].lon)\n",
    "                     for a in Buildings]\n",
    "    if(Buildings != []):\n",
    "        SetofAttributes.append(('id varchar(100) Primary Key', \n",
    "                                'floorArea varchar(100)', \n",
    "                                'buildingYear varchar(100)', \n",
    "                                'originalIdInSource varchar(100)',\n",
    "                                'surfaceArea varchar(100)',\n",
    "                                'name varchar(100)', \n",
    "                                'height varchar(100)', \n",
    "                                'Lat varchar(100)', \n",
    "                                'Lon varchar(100)'))\n",
    "        SetofTables.append('Buildings')\n",
    "        SetofValues.append(valBuildings)\n",
    "    \n",
    "        MapAssetToBuilding = [b for a in Buildings for b in a.asset]\n",
    "        valMapAssetToBuilding = [(b.id, b.name, a.id, a.name, '1') for a in Buildings for b in a.asset]\n",
    "        SetofAttributes.append(('id_Asset varchar(100) Primary Key', \n",
    "                                'name_Asset varchar(100)',  \n",
    "                                'id_Building varchar(100)',\n",
    "                                'name_Building varchar(100)', \n",
    "                                'Dummy varchar(100)'))\n",
    "        SetofTables.append('MapAssetToBuilding')\n",
    "        SetofValues.append(valMapAssetToBuilding)\n",
    "        \n",
    "    KPIs = esh.get_all_instances_of_type(esdl.KPI)\n",
    "    valKPIs = []\n",
    "    if(KPIs != []):\n",
    "        for k in KPIs:\n",
    "            valKPIs.append((k.id,k.name,k.value,'null','null','null','null'))\n",
    "        SetofAttributes.append(('id_KPI varchar(100)', \n",
    "                    'name_KPI varchar(100)', \n",
    "                    'value_KPI varchar(100)',\n",
    "                    'id_building varchar(100)',\n",
    "                    'name_building varchar(100)',\n",
    "                    'id_conversion varchar(100)',\n",
    "                    'name_conversion varchar(100)'))\n",
    "        SetofTables.append('KPIs')\n",
    "        SetofValues.append(valKPIs) \n",
    "    \n",
    "    KPIsBuildings = []\n",
    "    valKPIsBuildings=[]\n",
    "    if (Buildings != []):\n",
    "        for b in Buildings:\n",
    "            ks = b.KPIs           \n",
    "            if (ks):\n",
    "                KPIsBuildings.append(ks)\n",
    "                for i in range(len(ks.kpi)):\n",
    "                    temp = (ks.kpi[i].id, ks.kpi[i].name, ks.kpi[i].value,b.id, b.name, 'null','null')\n",
    "                    valKPIsBuildings.append(temp)\n",
    "    else:\n",
    "        for k in KPIs:\n",
    "            tup = (k.id, k.name, k.value,'null','null','null','null')\n",
    "            valKPIsBuildings.append(tup)\n",
    "            \n",
    "    if(valKPIsBuildings != []):    \n",
    "        SetofAttributes.append(('id_KPI varchar(100)', \n",
    "                    'name_KPI varchar(100)', \n",
    "                    'value_KPI varchar(100)',\n",
    "                    'id_building varchar(100)',\n",
    "                    'name_building varchar(100)',\n",
    "                    'id_conversion varchar(100)',\n",
    "                    'name_conversion varchar(100)'))\n",
    "        SetofTables.append('KPIsBuildings')\n",
    "        SetofValues.append(valKPIsBuildings)\n",
    "    \n",
    "    KPIConversions = []\n",
    "    valKPIConversions=[]\n",
    "    if (Conversions != []):        \n",
    "        for b in Conversions:\n",
    "            ks = b.KPIs\n",
    "            if (ks):\n",
    "                KPIConversions.append(ks)\n",
    "                for i in range(len(ks.kpi)):\n",
    "                    temp = (ks.kpi[i].id, ks.kpi[i].name, ks.kpi[i].value,'null','null',b.id, b.name, )\n",
    "                    valKPIConversions.append(temp)\n",
    "        \n",
    "        SetofAttributes.append(('id_KPI varchar(100)', \n",
    "                    'name_KPI varchar(100)', \n",
    "                    'value_KPI varchar(100)',\n",
    "                    'id_building varchar(100)',\n",
    "                    'name_building varchar(100)',\n",
    "                    'id_conversion varchar(100)',\n",
    "                    'name_conversion varchar(100)'))\n",
    "        SetofTables.append('KPIConversions')\n",
    "        SetofValues.append(valKPIConversions)\n",
    "        \n",
    "    CostInformations = esh.get_all_instances_of_type(esdl.CostInformation)\n",
    "    valCostInformations = []\n",
    "    for a in Assets:\n",
    "        c = a.costInformation    \n",
    "        if(a.costInformation):\n",
    "            temp = (a.id, a.name)\n",
    "            for d in dir(c):\n",
    "                e = getattr(c, d)\n",
    "                if e == None or type(e) == str:\n",
    "                    temp+= (None,)\n",
    "                else:\n",
    "                    temp+=(e.value,)\n",
    "            valCostInformations.append(temp)\n",
    "    CostInformationsAtt = ('AssetId varchar(100)', 'AssetName varchar(100)')\n",
    "    if(CostInformations != []):    \n",
    "        for d in dir(CostInformations[0]):\n",
    "            CostInformationsAtt += (d  + ' varchar(100)',)\n",
    "        SetofAttributes.append(CostInformationsAtt)\n",
    "        SetofTables.append('CostInformations')\n",
    "        SetofValues.append(valCostInformations)    \n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    Constraints = []\n",
    "    valConstraints = []\n",
    "    for a in Assets:\n",
    "        for b in a.constraint:\n",
    "            Constraints.append(b)\n",
    "            print(type(b.attributeReference))\n",
    "            temp = (a.id,a.name,b.id, b.name, b.attributeReference)\n",
    "            c = b.range\n",
    "            if(c):\n",
    "                temp += (c.id,c.name,c.minValue,c.maxValue)\n",
    "            else:\n",
    "                temp += (None,None,None,None)\n",
    "\n",
    "        \n",
    "            valConstraints.append(temp)\n",
    "                \n",
    "#             ('NodeId varchar(100)',\n",
    "#                       'NodeName varchar(100)',\n",
    "#                       ' varchar(100)',\n",
    "#                       'ConstraintName varchar(100)', \n",
    "#                       'ConstraintAttribute varchar(100)',\n",
    "#                       'RangeId varchar(100)', \n",
    "#                       'RangeName varchar(100)', \n",
    "#                       'minValue varchar(100)', \n",
    "#                       'maxValue varchar(100)')\n",
    "    if(Constraints != []):\n",
    "        SetofAttributes.append(('Node_Id varchar(100)',\n",
    "                      'Node_Name varchar(100)',\n",
    "                      'Constraint_Id varchar(100)',\n",
    "                      'Constraint_Name varchar(100)',\n",
    "                      'Constraint_Attribute varchar(100)', \n",
    "                      'range_Id varchar(100)',\n",
    "                      'range_name varchar(100)', \n",
    "                      'max varchar(100)', \n",
    "                      'min varchar(100)'))\n",
    "        SetofTables.append('Constraints')\n",
    "        SetofValues.append(valConstraints)\n",
    "    \n",
    "    \n",
    "    QuantityAndUnitTypes = esh.get_all_instances_of_type(esdl.QuantityAndUnitType)\n",
    "    valQuantityAndUnitTypes = []\n",
    "    valEnergyContentUnit = []\n",
    "    valEmissionUnits = []\n",
    "    for c in Carriers:\n",
    "        e = c.emissionUnit\n",
    "        if(e):\n",
    "            temp = (c.id, c.name, 'emissionUnit')\n",
    "            for d in dir(e):\n",
    "                a = getattr(e, d)\n",
    "                if a == None:\n",
    "                    temp+= (None,)\n",
    "                else:\n",
    "                    temp+=(a,)\n",
    "            valEmissionUnits.append(temp)\n",
    "            valQuantityAndUnitTypes.append(temp)\n",
    "        if c not in Commodities:\n",
    "            f = c.energyContentUnit\n",
    "            if(f):\n",
    "                temp = (c.id, c.name, 'energyContentUnit')\n",
    "                for d in dir(f):\n",
    "                    a = getattr(f, d)\n",
    "                    if a == None:\n",
    "                        temp+= (None,)\n",
    "                    else:\n",
    "                        temp+=(a,)\n",
    "                valEnergyContentUnit.append(temp)\n",
    "                valQuantityAndUnitTypes.append(temp)\n",
    "            \n",
    "            \n",
    "    \n",
    "    QuantityAndUnitTypesAtt = ('CarrierId varchar(100)', 'CarrierDescription varchar(100)', 'type varchar(100)')\n",
    "    if(QuantityAndUnitTypes != []): \n",
    "        for d in dir(QuantityAndUnitTypes[0]):\n",
    "            QuantityAndUnitTypesAtt += (d + ' varchar(100)',)\n",
    "        SetofAttributes.append(QuantityAndUnitTypesAtt)\n",
    "        SetofTables.append('QuantityAndUnitTypes')\n",
    "        SetofValues.append(valQuantityAndUnitTypes)\n",
    "        \n",
    "#     GenericProfiles = esh.get_all_instances_of_type(esdl.GenericProfile)\n",
    "#     valGenericProfiles = [(p.profileType, \n",
    "#                            p.profileQuantityAndUnit,\n",
    "#                            p.name,\n",
    "#                            p.interpolationMethod,\n",
    "#                            p.dataSource,\n",
    "#                            p.setProfile,\n",
    "#                            p.id,\n",
    "#                            p.getProfile)\n",
    "#                            for p in GenericProfiles]              \n",
    "#     SetofAttributes.append(('profileType varchar(100)',\n",
    "#                           'profileQuantityAndUnit varchar(100)',\n",
    "#                           'name varchar(100)',\n",
    "#                           'interpolationMethod varchar(100)',\n",
    "#                           'dataSource varchar(100)',\n",
    "#                           'setProfile varchar(100)',\n",
    "#                           'id varchar(100) Primary Key',\n",
    "#                           'getProfile varchar(100)'))\n",
    "#     SetofTables.append('GenericProfiles')\n",
    "#     SetofValues.append(valGenericProfiles)\n",
    "    \n",
    "#     SingleValues = esh.get_all_instances_of_type(esdl.SingleValue)\n",
    "#     valSingleValues = [(p.id, p.value) for p in SingleValues]\n",
    "#     SetofAttributes.append(('id varchar(100) Primary Key', 'value varchar(100)'))\n",
    "#     SetofTables.append('SingleValues')\n",
    "#     SetofValues.append(valSingleValues)\n",
    "    \n",
    "    \n",
    "\n",
    "    create_AIMMS_sql(DB,SetofTables,SetofAttributes)\n",
    "    \n",
    "#   for loop that writes the tuple of values to the new database in the corresponding table.\n",
    "    for a in range(len(SetofTables)):\n",
    "        print('Exporting:',SetofTables[a])\n",
    "        write_table_to_Sql(DB, SetofTables[a], SetofValues[a])\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff151a29",
   "metadata": {},
   "source": [
    "### Main function that loads an Loads an ESDL file and restructures the data such that the function above can write everything in a newly created SQL Database. The restructuring gets set in SetofTables, SetofAttributes    SetofValues. With SetofTables a list, SetofAttributes a list of tuples and SetofValues a list of a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49220907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arcs\n",
      "Arcs : \n",
      "    connectedTo\n",
      "    energyasset\n",
      "    name\n",
      "    maxPower\n",
      "    id\n",
      "    simultaneousPower\n",
      "    profile\n",
      "    carrier\n",
      "    constraint\n",
      "Assets\n",
      "Assets : \n",
      "    port\n",
      "    type\n",
      "    commissioningDate\n",
      "    consType\n",
      "    controlStrategy\n",
      "    sector\n",
      "    dataSource\n",
      "    description\n",
      "    shortName\n",
      "    capacity\n",
      "    isOwnedBy\n",
      "    state\n",
      "    bufferDistance\n",
      "    operationalHours\n",
      "    inverterEfficiency\n",
      "    prodType\n",
      "    voltage\n",
      "    installationDuration\n",
      "    KPIs\n",
      "    geometry\n",
      "    power\n",
      "    fullLoadHours\n",
      "    behaviour\n",
      "    numberOfPanels\n",
      "    aggregationCount\n",
      "    manufacturer\n",
      "    panelEfficiency\n",
      "    containingAsset\n",
      "    originalIdInSource\n",
      "    material\n",
      "    decommissioningDate\n",
      "    surfaceArea\n",
      "    angle\n",
      "    powerFactor\n",
      "    name\n",
      "    id\n",
      "    efficiency\n",
      "    technicalLifetime\n",
      "    assetType\n",
      "    aggregated\n",
      "    containingBuilding\n",
      "    orientation\n",
      "    costInformation\n",
      "    owner\n",
      "    minPower\n",
      "    area\n",
      "    constraint\n",
      "Carriers\n",
      "Carriers : \n",
      "    name\n",
      "    cost\n",
      "    id\n",
      "    emission\n",
      "    voltage\n",
      "    dataSource\n",
      "    emissionUnit\n",
      "    renewableFactor\n",
      "Commodities\n",
      "Commodities : \n",
      "    name\n",
      "    cost\n",
      "    id\n",
      "    emission\n",
      "    voltage\n",
      "    dataSource\n",
      "    emissionUnit\n",
      "    renewableFactor\n",
      "Constraints\n",
      "Constraints : \n",
      "    isOwnedBy\n",
      "    range\n",
      "    name\n",
      "    id\n",
      "    attributeReference\n",
      "    originalIdInSource\n",
      "    sector\n",
      "    dataSource\n",
      "    description\n",
      "    shortName\n",
      "ConsumerProfiles\n",
      "ConsumerProfiles : \n",
      "    port\n",
      "    measurement\n",
      "    setProfile\n",
      "    name\n",
      "    startDate\n",
      "    id\n",
      "    endDate\n",
      "    filters\n",
      "    database\n",
      "    host\n",
      "    multiplier\n",
      "    profileQuantityAndUnit\n",
      "    interpolationMethod\n",
      "    dataSource\n",
      "    getProfile\n",
      "    profileType\n",
      "    field\n",
      "Consumers\n",
      "Consumers : \n",
      "    port\n",
      "    commissioningDate\n",
      "    consType\n",
      "    controlStrategy\n",
      "    sector\n",
      "    dataSource\n",
      "    description\n",
      "    shortName\n",
      "    isOwnedBy\n",
      "    state\n",
      "    bufferDistance\n",
      "    installationDuration\n",
      "    KPIs\n",
      "    geometry\n",
      "    power\n",
      "    behaviour\n",
      "    aggregationCount\n",
      "    manufacturer\n",
      "    containingAsset\n",
      "    originalIdInSource\n",
      "    material\n",
      "    decommissioningDate\n",
      "    surfaceArea\n",
      "    powerFactor\n",
      "    name\n",
      "    id\n",
      "    technicalLifetime\n",
      "    assetType\n",
      "    aggregated\n",
      "    containingBuilding\n",
      "    costInformation\n",
      "    owner\n",
      "    area\n",
      "    constraint\n",
      "CostInformations\n",
      "CostInformations : \n",
      "    developmentCosts\n",
      "    id\n",
      "    variableOperationalAndMaintenanceCosts\n",
      "    marginalCosts\n",
      "    investmentCosts\n",
      "    variableOperationalCosts\n",
      "    variableMaintenanceCosts\n",
      "    discountRate\n",
      "    fixedOperationalCosts\n",
      "    fixedOperationalAndMaintenanceCosts\n",
      "    fixedMaintenanceCosts\n",
      "    installationCosts\n",
      "ElectricityCommodities\n",
      "ElectricityCommodities : \n",
      "    name\n",
      "    cost\n",
      "    id\n",
      "    emission\n",
      "    voltage\n",
      "    dataSource\n",
      "    emissionUnit\n",
      "    renewableFactor\n",
      "Producers\n",
      "Producers : \n",
      "    port\n",
      "    type\n",
      "    commissioningDate\n",
      "    controlStrategy\n",
      "    sector\n",
      "    dataSource\n",
      "    description\n",
      "    shortName\n",
      "    isOwnedBy\n",
      "    state\n",
      "    bufferDistance\n",
      "    operationalHours\n",
      "    inverterEfficiency\n",
      "    prodType\n",
      "    installationDuration\n",
      "    KPIs\n",
      "    geometry\n",
      "    power\n",
      "    fullLoadHours\n",
      "    behaviour\n",
      "    numberOfPanels\n",
      "    aggregationCount\n",
      "    manufacturer\n",
      "    panelEfficiency\n",
      "    containingAsset\n",
      "    originalIdInSource\n",
      "    material\n",
      "    decommissioningDate\n",
      "    surfaceArea\n",
      "    angle\n",
      "    powerFactor\n",
      "    name\n",
      "    id\n",
      "    technicalLifetime\n",
      "    assetType\n",
      "    aggregated\n",
      "    containingBuilding\n",
      "    orientation\n",
      "    costInformation\n",
      "    owner\n",
      "    minPower\n",
      "    area\n",
      "    constraint\n",
      "QuantityAndUnitTypes\n",
      "QuantityAndUnitTypes : \n",
      "    physicalQuantity\n",
      "    perMultiplier\n",
      "    id\n",
      "    perTimeUnit\n",
      "    multiplier\n",
      "    unit\n",
      "    perUnit\n",
      "    perScope\n",
      "    description\n",
      "Transports\n",
      "Transports : \n",
      "    port\n",
      "    commissioningDate\n",
      "    controlStrategy\n",
      "    sector\n",
      "    dataSource\n",
      "    description\n",
      "    capacity\n",
      "    shortName\n",
      "    isOwnedBy\n",
      "    state\n",
      "    bufferDistance\n",
      "    voltage\n",
      "    installationDuration\n",
      "    KPIs\n",
      "    geometry\n",
      "    behaviour\n",
      "    aggregationCount\n",
      "    manufacturer\n",
      "    containingAsset\n",
      "    originalIdInSource\n",
      "    material\n",
      "    decommissioningDate\n",
      "    surfaceArea\n",
      "    name\n",
      "    efficiency\n",
      "    id\n",
      "    technicalLifetime\n",
      "    assetType\n",
      "    aggregated\n",
      "    containingBuilding\n",
      "    costInformation\n",
      "    owner\n",
      "    area\n",
      "    constraint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "conn = pymysql.connect(\n",
    "    host= Host,\n",
    "    user=User,\n",
    "    password=PW)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def str_to_class(classname):\n",
    "    return getattr(sys.modules[__name__], classname)\n",
    "\n",
    "\n",
    "def Check_dir(my_class):\n",
    "    Attributes = [dir(n) for n in my_class]\n",
    "    AllAttributes = set(sum(Attributes, []))\n",
    "    return AllAttributes\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    #The next set contains all the ESDL classes that have been included in the last main function\n",
    "    ThingsInESDL = get_sql(\"Select table_schema as database_name, table_name from information_schema.tables where table_type = 'BASE TABLE'and table_schema = '\" + DB + \"' order by database_name, table_name;\").table_name\n",
    "    for i in ThingsInESDL:\n",
    "        print(i)\n",
    "        dirThing = Check_dir(str_to_class(i))\n",
    "        print(i, ': ')\n",
    "        for j in dirThing:\n",
    "            print('   ',j)\n",
    "    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2161cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b485f1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d76759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b29fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5f2ec",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Space for AIMMS Rest API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9b7c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cd1b034",
   "metadata": {},
   "source": [
    "# Class that reads the SQL back in. Used to check if the data is ordered correctly and edits the ESDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15fdb8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n",
      "C:\\Users\\Stijn\\AppData\\Local\\Temp\\ipykernel_10916\\3945251358.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arcs', 'Assets', 'Carriers', 'Commodities', 'Constraints', 'ConsumerProfiles', 'Consumers', 'CostInformations', 'DB', 'ElectricityCommodities', 'Producers', 'QuantityAndUnitTypes', 'Transports', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'getAttributes', 'tables']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SQLESDL' object has no attribute 'Processes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m Training \u001b[38;5;241m=\u001b[39m SQLESDL(Schema)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(Training\u001b[38;5;241m.\u001b[39mgetAttributes())\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mTraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcesses\u001b[49m)\n\u001b[0;32m     27\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SQLESDL' object has no attribute 'Processes'"
     ]
    }
   ],
   "source": [
    "conn = pymysql.connect(\n",
    "    host= Host,\n",
    "    user=User,\n",
    "    password=PW)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "class SQLESDL:\n",
    "    def __init__(self, DB):\n",
    "        self.tables = get_sql(\"Select table_schema as database_name, table_name from information_schema.tables where table_type = 'BASE TABLE'and table_schema = '\" + DB + \"' order by database_name, table_name;\")\n",
    "        self.DB= DB\n",
    "        \n",
    "        for i in self.tables.table_name:\n",
    "            setattr(self, i,get_sql('SELECT * FROM '+DB+'.'+i+ ';'))\n",
    "\n",
    "    \n",
    "    def getAttributes(self):    \n",
    "        return dir(self)\n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    Schema = DB\n",
    "    Training = SQLESDL(Schema)\n",
    "    print(Training.getAttributes())\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "900d38fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c1163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c6559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fa4e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d017662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc2119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ca656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df56e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e554f94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ebdb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f1d5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f369c39c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
